<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Advanced Python Theory on Yzzhan Tech Repo</title>
    <link>https://yangzhanghavefun.github.io/yzzhan/categories/advanced-python-theory/</link>
    <description>Recent content in Advanced Python Theory on Yzzhan Tech Repo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you wish to quote or reproduce.</copyright>
    <lastBuildDate>Sat, 16 Mar 2019 01:37:56 +0800</lastBuildDate>
    
	<atom:link href="https://yangzhanghavefun.github.io/yzzhan/categories/advanced-python-theory/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>对Elastic Search的实现和理解</title>
      <link>https://yangzhanghavefun.github.io/yzzhan/post/search_engine/</link>
      <pubDate>Sat, 16 Mar 2019 01:37:56 +0800</pubDate>
      
      <guid>https://yangzhanghavefun.github.io/yzzhan/post/search_engine/</guid>
      <description> Elastic Search Engine Specification  Coding Language : python FrameWork : django + scrapy Scrapied website: www.zhihu.com www.jobbole.com www.lagou.com  Knowledge Preparation 浏览器 driver 由于知乎等网站需要登录后才能访问所需要的内容，于是我们需要安装chrome driver 和 selenium去模拟登录
下载链接 http://chromedriver.chromium.org/downloads 但是，直接使用还是凉凉， 因为服务器会从Chrome driver的某些js文件中检测出这是个driver不是正常浏览器，然后返回403.我们的解决方法是开启chrome remote debug 模式 配置 关闭所有chrome正在运行的实例 在Cmd里找到Chrome.exe所在的目录，输入chrome.exe &amp;ndash;remote-debugging-port=9222 然后访问127.0.0.1:9222/json
ElasticSearch 概念  集群： 一个或多个节点组织在一起 节点： 一个节点是集群中的一个服务器，由一个名字来标识 分片： 将索引划分为多份的能力，允许水平分割和扩展容量，多个分片响应请求，提高性能和吞吐量 副本： 创建分片的一份或多份的能力，在一个节点失败是其余节点可以顶上     ElasticSearch Mysql     index(索引) 数据库   type(类型) 表   documents(文档) 行   Fields 列    </description>
    </item>
    
    <item>
      <title>如何在python环境实现并发和一些对并发的理解</title>
      <link>https://yangzhanghavefun.github.io/yzzhan/post/coroutine/</link>
      <pubDate>Wed, 16 Jan 2019 01:37:56 +0800</pubDate>
      
      <guid>https://yangzhanghavefun.github.io/yzzhan/post/coroutine/</guid>
      <description>概念： 并发，并行，同步，异步，阻塞， 非阻塞 并发的开发 &amp;mdash; 回调 + 事件循环 + select(poll,epoll) import socket from urllib.parse import urlparse from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE selector = DefaultSelector() urls = [&amp;#34;https://www.baidu.com&amp;#34;, &amp;#34;https://www.baidu.com&amp;#34;] stop = False class Fetcher: def connected(self, key): selector.unregister(key.fd) self.client.send(&amp;#34;GET {} HTTP/1.1\r\nHost:{}\r\nConnection:close\r\n\r\n&amp;#34;.format(self.path, self.host).encode(&amp;#34;utf8&amp;#34;)) # 当写入成功时，我们继续注册selector用以接受请求的回答 selector.register(self.client.fileno(), EVENT_READ, self.received) def received(self, key): d = self.client.recv(1024) if d: self.data += d else: selector.unregister(key.fd) data = self.data.decode(&amp;#34;utf8&amp;#34;) html_data = data.split(&amp;#34;\r\n\r\n&amp;#34;)[1] print(html_data) self.client.close() urls.remove(self.next_url) if not urls: global stop stop = True def get_url(self, url): self.</description>
    </item>
    
    <item>
      <title>实现高并发并深入理解asyncio内置包</title>
      <link>https://yangzhanghavefun.github.io/yzzhan/post/asyncio/</link>
      <pubDate>Wed, 16 Jan 2019 01:37:56 +0800</pubDate>
      
      <guid>https://yangzhanghavefun.github.io/yzzhan/post/asyncio/</guid>
      <description>Package Asynic 实现协程和io多路复用，python提供了一个内置包&amp;mdash;asyncio去简化 回调+事件循环(核心)+select(poll,epoll)这个流程。
在async包的内部，已经实现了事件循环，并且为了把generator和coroutine方法区分开，python引入了两个关键词 async和await
-async用于方法开头，声明此方法为协程方法
-await用于方法中，声明需要异步处理的地方，类似于生成器里的yield from
-同时方法末尾可提供一个返回值。
-在协程方法中不可以使用同步/阻塞的方法或函数(eg: time.sleep() &amp;mdash;&amp;gt; async.sleep())，否则会使异步编程无意义
Adding tasks into loop  我们实例化loop &amp;mdash;&amp;gt; loop = asyncio.get_event_loop()
 然后列出需要异步实现的Tasks. 此时我们有两种实现方法。第一我们可以把我们的task转成Future object eg: ``python futures = [asyncio.ensure_future(get_html(&amp;quot;www.baidu.com/{}&amp;quot;.format(i))) for i in range(100)]
  for future in futures: future.add_done_callback(callbakck)
 这个方法与线程池的实现方法和原理相同，在future object里存着返回的值，并用result()可以调出。并且，future object支持增加回调函数.当我们的回调函数需要输入参数时，我们需要用到包装函数partial ---- from functools import partial ```python for future in futures: future.add_done_callback(partial(callbakck, &amp;quot;www.baidu.com&amp;quot;))  或者用async.wait, async.gather包装
task_group_1 = [get_html(&amp;#34;www.bilibili.com/{}&amp;#34;.format(i))for i in range(10)] task_group_2 = [get_html(&amp;#34;www.</description>
    </item>
    
    <item>
      <title>对多线程的理解和深入理解Future源码</title>
      <link>https://yangzhanghavefun.github.io/yzzhan/post/multithreads/</link>
      <pubDate>Wed, 16 Jan 2019 01:37:56 +0800</pubDate>
      
      <guid>https://yangzhanghavefun.github.io/yzzhan/post/multithreads/</guid>
      <description>Basic Concepts related to thread and process Multiple ways to implement the multithreading project in python Queue, Lock, RLock, Condition and Semorpher # GIL---global interpreter lock import threading from queue import Queue import time # Communication between threads # 1. Share Variables sum = 0 lock = threading.Lock() def add_glo(lock): global sum for i in range(1000000): lock.acquire() sum += 1 lock.release() def dec_glo(lock): global sum for i in range(1000000): lock.</description>
    </item>
    
  </channel>
</rss>