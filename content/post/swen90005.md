---
title: "Modelling Complex System(SWEN90005)"
tags: ["java", "FSP", "Complex System"]
date: 2019-6-22
draft: false
---

## Concurrency
Concurrent programming needs to handle two types of difficulties.

- Communication: Process generally need to communicate with each other, either by accessing shared data, or by message passing.
- Synchronization: Process may need to synchronize certain events, such as "P must not reach point P until after Q has reached point Q".

Here are two solutions to solve the difficulites.

- Shared memory: utilising the concept of monitor.
- Message Passing: based on Hoare's idea of Communication Sequential Processes(CSP)

### Shared Memorry --- Java

The processors go wrong because each falsely assumes to have exclusive access to memorry in its read-change-write cycle. This is known as **interference** or a **race condition**. It justifies our interest in **mutual exclusion**. A concurrent program must be correct for all possible interleavings.

```Java
public class UseMyThread {
    public static void main(String[] args){
        Thread myThread = new MyThread();
        myThread.start();
    }
}
```
The call to start() causes the new Thread to call its run() method and execute it independently of the caller.

Java thread state 
![](/media/posts/th_state.png)

- yield(): causes the current thread to pause, going from _RUNNING_ to _RUNNABLE_
- t.join(): suspends the caller until thread t has completed.
- wait(): waits for a lock to be released

A thread can be interrupted through Thread.interrupt(). If interrupted in one of the three states above, it will return to _RUNNABLE_ state, and then sleep(), or join(), or wait() will throw an InterruptedException.

Desirable properties of a Mutex solution

- Mutual exclusion: only one process may be active in its critical section at a time.
- No deadlock: if one or more processor are trying to enter their critical section, one must eventually succeed.
- No starvation:
- Handles lack of contention: if only one process is trying to enter its critical section, it must succeed with minimal overhead.

**Semaphore**

Semaphore is a simple but versatile concurrent device for managing access to a shared resource. It consist of a value V which is currently available access permits, and a wait set W of processes currently waiting for access.

**Synchronization and Monitors**
Synchronized is keyword in Java, which aims to declare that there is only one process can execute or modify it at any one time.

Monitors are a set of synchronized methods and data(an object or module) that queue processes trying to access the data. critical section is a synchronized part of code. 

Monitors are language features that helps with providing mutual exclusion to shared data. In Java, a monitor is an object that encapsulates some (private) data, with access to the data only via synchronized methods.

Every object in java contains a monitor and three methods to operate, wait(), notify() and notifyAll().

Therefore, a more detailed state digram for java thread shows here.
![](/media/posts/detailed_state_java.png)

### Message Passing --- Go
Communication requires two processes: one to send a message and one to receive it.

In Go,

- processes are called go-routines. A go-routine is a function that is executed independently.
- allows for go-routines to communicate via shared viariables but not recommand
- go-routines usually communicate by sending and receiving data on **named channels**.
- **Channel** is a communication pipe; it can be one-way or two-way. A Channel is typed and can carry data of all sorts of type.
- A "<-" indicates how a channel is being used
## Concurrency Modelling --- FSP

### Fundamental concepts
#### input and output
#### non-deterministic choice
#### indexed processes
#### constants and ranges
#### guarded actions

#### parallel composition
#### shared actions
#### action relabelling
#### process labelling
#### Liveness and Safety
##### Deadlock

Causes:

- **Serially resusable resources**: the processes involved must have some reusable resources between themselves under mutual exclusion.
- **Incremental acquisition**:  process hold on to resources that have been allocated to them while waiting for additional resources.
- No preemption: once a process has acquired a resource, it can only release it voluntarily -- it cannot be forced to release it
- Wait-for cycle: a cycle exists in which each process holds a resource which its successor in the cycle is waiting for.

- Safety property: is that the system satisfies some assertion each time a given program point is reached.
- Liveness property: is that the system terminates for a sequential system.

##### Safety --- property --- deadlock

##### Liveness --- progress --- livelock
We assert progress in FSP using a **progress** property
> progress P = {a1, a2, ..., aN} defines a progress property P that asserts that, in an infinite execution of a target system, at least one of the actions a1, a2, ..., aN will be executed infinitely often.

#### Action Priority

The high priority operator P<<{a1,...aN} specifies that actions a1,...,aN have a higher priority than all other actions in P.
The low priority operator P>>{a1,...aN} specifies that actions a1,...,aN have a lower priority than all other actions in P.
#### Temporal logic
We are interested in properties about sequences of actions over time, not just one instant of time.

Temporal logics allow us to talk about durations and the relative times of events.

A **fluent** is a property that can change over time. Fluents allow us to describe properties of a system over its lifetime, rather than at just one instant. Fluents are used heavily in logic, especially artificial in logic, especially artificial intelligence.

```Ruby
fluent FL = <{s1,...,sN}, {e1,...,eN}>
```
s1,...,sN and e1,...,eN are actions. The fluent FL is the proposition, and FL becomes true when any of the actions in {s1,...,sN} occur, and then false again when any of the actions in {e1,...,eN} occur. FL is initially false.

If we want a fluent that is initially true, we can describe it using:
```Ruby
fluent FL = <{s1,...,sN}, {e1,...,eN}> initially 1
```

**indexed fluents**
```Ruby
fluent GREEN[i:1..2] = <{green[i]}, {yellow[i],red[i]}> initially 1
```

**Fluent expressions**
We want to express that we do not want the two lights to be green at the same time
```Ruby
!forall[i:1..2] GREEN[i]

!(GREEN[1] && GREEN[2])

exists[i:1..2] !GREEN[i]
```
```Ruby
fluent GREEN = <{green}, {yellow, red}> initially 1
fluent YELLOW = <{yellow}, {green, red}> initially 0
fluent RED = <{red}, {yellow, green}> initially 0
```
**Tomporal Logic -- always**
Now to say that the light is always green, yellow, or red
```Ruby
assert ALWAYS_A_COLOUR = [](GREEN || YELLOW || RED)
```
**Tomporal Logic -- eventually**
This fluent says that the light will eventually become red:
```Ruby
assert EVENTUALLY_RED = <>RED
```

The **always** operator is used to describe safety properties.
The **eventually** operator is used to describe liveness properties.

**Tomporal Logic -- until**
The **until** operator allows us to specify that a certain property is true until another property becomes true

In our traffic system, the light is initially green, and stays green until the button is pushed.
```Ruby
assert INITIALLY_GREEN = (GREEN U button)
```
**Tomporal Logic -- next**
The **next** operator allows us to specify that a certain property is true at the next instant.

We can specify that when the button is pushedm the light will go  yellow at the next time instant.
```Ruby
assert BUTTON_TO_YELLOW = (button -> X YELLOW)
```
## Complex System
Complex system 
: A set of things working together as parts of a mechanism or an interconnecting network

- two body problem:
  - can be solved analytically
  - produces regular trajectories
- three body problem:
  - no exact mathematical solution
  - produce chaotic trajectories

- low-dimensional chaos
  - the logistic equation: $x_{n+1}=rx_{n}$
  - The logic mao is an example of a relatively simple dynamical equation that can give rise to broad range of complex emergent behaviors.
- crystals and gases
  - highly ordered and regular(crystal)
  - highly disordered but statistically homogeneous(gas)
  - In contrast to the preceding systems, these examples consist of many interacting parts. The rules for thier interaction are relatively simple

### Dynamic system
A dynamic system consists of:
- a set of possible states(the state space)
- time t
- a rule that determines the state at the present time($x_{t}$) in terms of states at earlier times($x_{t-1},x_{t-2},x_{t-3}$)

To model a dynamic system, we define: 
- our system variables and the states they can take
- the function that computes the next state

This will usually involve simplifying assumptions about the real world. When exploring the behaviour of our model, we need to evaluate it against what we know about the real system. This may result in us refining our model.

- assumptions
- states
- update rules

Dynamical systems have several different types of characteristic behaviours.

- fixed points
- limit cycles
- aperiodic orbits(chaos)

Dynamic systems that a system exhibits can depend critically on the values of system parameters.

#### Functions and Iteration
A function takes a number as an input, does sth to it, and produces a number as an output.

Iteration is simply using the output of the previous application of a function as the input for the next application.

#### Chaos
A system is chaotic if it displays all of the following our properties:

- The dynamical update rule is deterministic.
- The system behaviour is aperiodic.
- The system behaviour is bounded.
- The system displays sensitivity to initial condition.


### ODE Model I -- Predator-Prey
- building a mathematical model
  - starting with a simple model
  - extending models to include additional aspects of real world
- Models
  - population growth
  - spcies interation(predator-prey)
- representing behaviour of dynamic systems
  - time series plots(how system changes over time)
  - phase portraits(how state variables change with respect to each other)
- exploring behaviour
  - numerically
  - analytically
#### The Lotka-Volterra Model

Model formulation

- Prey(rabbits): $\frac{dR}{dt} = \alpha R - \beta RF$
- Predator(red foxes): $\frac{dF}{dt}= \delta RF - \gamma F$

- $\alpha$: growth rate of the rabbit population
- $\beta$: rate at which foxes predate upon (eat) rabbits
- $\delta$: growth rate of the fox population
- $\gamma$: decay rate of the fox population due to death and migration

> Solving ODE(ordinary differential equations) 
> First approach: Euler method
> Second approach: Runge-Kutta method

- The lag between the peaks in the predator and prey population

equilibria
: points at which the system variables(the population level R and F)do not change ie. where $\frac{dF}{dt}=0$ and $\frac{dR}{dt}=0$

There are two equilibria:
- R = 0, F = 0
  - saddle point ?
  - both populations are extinct
  - it is unstable; it can only arise if the prey level is set to zero, at which point the predators also die out.
- R = $\gamma / \delta$ F = $\alpha / \beta$
  - both populations sustained at non-zero levels indefinitely.
  - It is stable specifically, it is neutrally stable, and surrounded by infinitely many periodic orbits

- The amplititude of the environment constantly changes, with the result that the system location in the phase plane will consistently switch from one orbit to another. This is unrealistic.
- Real cycles tend to have a 'characteristic' amplitude.

##### Lotka-Volterra model with competition

- The logistic equation captured intraspecific competition
- The base Lotka-Volterra model captures interspecific competition 

new equation should be:
$\frac{dR}{dt} = \alpha R - \beta RF - aR^{2}$
$\frac{dF}{dt} = \delta RF - \gamma F - bF^{2}$

Other possible issue:
- The relation between the predator's consumption rate and prey density
- The efficiency with which extra food is tranformed into extra predators
- The spatial distribution of species will play a role.


The n-species competitive model can be written as:
$\frac{dx_{i}}{dt} = r_{i}x_{i}(1- \sum^{N}_{j=1}a_{ij}x_{j}/K_{i})$

where $x_{i}$ represents the i-th species and $a_{ij}$ is a matrix of interaction terms.

Dynamic systems can exhibit different types of long-term behaviour, including **fixed points** and **limit cycles**

Fixed points and limit cycles can be:

- stable and attracting
- unstable and repelling

A single dynamic system can exhibit multiple stable and unstable fixed points.

In a system with more than one stable fixed point, the lont-term behaviour will depend on the initial conditions

The set of initial conditions that approach an attractor are known as a basin of attraction.

### ODE Model II -- Epidemics

Infectious disease models are dynamic models.

A model has a state, which describes all relevant aspects of the system at a particular point in time

A model has update rules, which describe how the state of a model changes over time.

These rules often involve parameters.

The SIR(Susceptible, Infectious, Recovered) model is one of the simplest disease models 

- Susceptible: can be infected
- Infectious: can infect others
- Recovered: can not be infected nor infect others

#### basic model

1. If they are susceptible, and they encounter an infectious person, they may be infected.
2. If they are infectious, they may recover

- State: N=10 people with a state S,I or R
- Initial condition: Day 0, 9 S and 1 I
- Rules: Everyday, everybody will meet each other.
  - Infection: each time a susceptible person meets an infectious person, they have a probability q of becoming on the next day.
  - Recovery: an infectious person will recover on the next day with probability $\gamma$
- Parameters: q and $\gamma$

A key concept in infectious disease epidemiology is the reproduction number R, often defined as the average numebr of secondary cases infected by a typical primary case.

The basic reproduction number $R_{0}$ is the average number of secondary cases infected by a typical primary case in a totally susceptible population.

The reproduction number can tell us whether an outbreak can occur:

- if $R_{0}$ < 1, then the outbreak will die out
- if $R_{0}$ > 1, then the outbreak may take off.

Comparison between stochastic models and deterministic models.

- Stochastic models
  - non-deterministic in that a state does not fully determine the next state
  - Each time we observe a different outcome.
  - as population size increases, the influence of chance diminishes.
  - more computation - more suited to small populations (or small number of infectious people)
  - provides information on distribution of outcomes
- Deterministic models
  - generate unique outcomes based on a given set of parameters and initial condition.
  - for each state of a deterministic model, there is only one possible future state.
  - more efficient to run - can explore more parameters
  - analysis can provide more general insights
  - only applicable when certain conditions hold

### From macro to micro

Complex systems are systems whose behaviour emerges from interactions between many individual parts.

The ODE models of these systems requried us to represent their state in terms of global variables, and to define update rules in terms of how these global variables changed over time.

In discussing possible problems with thees models, these assumptions kept coming up as limitations.

We could extend our ODE models to reflect this heterogeneity(variation between individuals), but the number of equations and parameters requried would explode rapidly.

Therefore, we are going to explore approaches to modelling that are capable of representing this heterogeneity in populations.

### Cellular Automata

Cellular Automata are a type of discrete dynamical system that exhibit complex behaviour based on simple, local rules.

Automation
: a theoretical machine that updates its internal state based on external inputs and its own previous state.

Cellular automation
: an array of automata(cells), where the inputs to one cell are the current states of nearby cells

In a CA:

- time is discrete
- space is discrete
- system state is discrete
- update rules are defined in terms of local interactions between components

Each finite automata consists of a finite set of cell states $\sum$, a finite input alphabet $\alpha$ and a transition function $\triangle$, which is a mapping from the set of neighbourhood states to the set of cell states:

$\triangle=\sum^{N} \rightarrow N$

The size of $\alpha$ is equal to the number of possible neighbourhood states:
$|\alpha|=|\triangle|=|\sum^{N}|=K^{N}$

Since there are K = $|\sum|$ choices of states to assign as the next state for each of the $|\sum^{N}|$ possible neighbour states, there are $K^{K^{N}}$ possible transitions functions $\triangle$ that can be defined.

Cellar Automata(CA) as a formalism for modelling complex systems.

- Compared to the ODE models, they are bottom up rather than top down.
- Complex system characteristics:
  - many interacting parts
  - parallel distributed processing
  - state updates are determined by local rules and interactions
  - complex global behaviour emerges
- Can be suited for modelling systems where "macro-rules" are hard to identify.
- But, not straight forward to analyse behaviour
- Good to test if local mechanism X generate phenomenon Y.

#### Model Implementation
- Space
  - discrete vs. continuous space
  - single vs. multiple occupancy of cells
  - proximate vs long-range interaction
- Time
  - the order of updation(Sychronous updating/Asynchronous updating)
  - discrete vs. continuous time
- Information
  - Scope of variable
  - range of sensing
- State updating
  - stochastic: randomness involved 
  - deterministic: future state of a component be uniquely specified by its current inputs.

---

- Asychronous CA: The basic CA updates all cells synchronously (at the same time) at every time step. We could also update cells at different times.
- Probabilistic CA: The basic CA update rules are deterministic (Cx.05 examples). We could also use update rules that are probabilistic/stochastic (Cx.06 examples).
- Non-homogeneous CA: The basic CA applies the same update rule to every cell. We could also use context-sensitive rules.
- Network-structured CA: The basic CA defines neighbourhood in terms of grid adjacency. We could also use a more complex network topology of neighbours.
---
- Advantages: 
  - they are simple and easy to implement
  - they can represent interactions and behaviours that are difficult to model using ODEs
  - they reflect the intrinsic individuality of system components
- Disadvantages:
  - they are relatively constrained (topology, interactions, individual behaviour)
  - the global behaviour may be difficult to interpret

### Agent-based Model

Like cellular(CA), agent-based models(ABMs) are an approach to modelling complex systems taht focuses on the components of the system and the interactions between them

The goal of ABMs is often to provide explanatory insight into the way real world complex systems work.

An ABM typically has three elements:

- agents 
- environment 
- interactions

Agent-based models consist of agents, an environment, and interactions between agents and other agents and the environments.

ABMs feature decentralised information and decision making. ABMs can be much more elaborate than CAs.


Rules for flocking behaviour

1. Seperation: birds will steer to avoid crowding nearby birds --- collision avoidance
2. Cohesion: birds will steer towards the average location of nearby birds --- safety in numbers
3. Alignment: Birds will steer toward the average bearing of nearby birds.

#### Characteristics of Agents

##### Essential characteristics: Self-contained
An agent is a modular component of a system, which has a boundary and can be clearly distinguished from and recognized by other agents.

##### Essential characteristics: Autonomous
An agent can function independently in its environment, and in its interactions with other agents

##### Essential characteristics: Dynamic State
An agent has attributes or variables, that can change over time. An agents current state is what determines its future action and behaviour

##### Essential characteristics: Social
An agent dynamic interactions with other agents: that influence their behaviour.

##### Other characteristics: adaptive
An agent may have the ability to learn and adapt its bahaviour on the basis of its past experiences

##### Other characteristics: goal-directed
An agent may have goals that it is attempting to achieve via its behaviours

##### Other characteristics: heterogeneous
A system may be comprised of agents of different types: these differences may be by design or a result of an agents' past history.

#### Environments

- Agents monitor and react to their environment
- Environments may be static, or they may change as a result of agent behaviour, or they may be independently dynamic
- Real environments are typically dynamic. Therefore we may not be able to foresee all possibel 'state' of the environment and how agents will respond to them.
- Richer environments may be continuous and involve multiple layer detailing and complex feedback loops.

#### Interactions

- direct or indirect
- agent neighbourhood: local interaction between agents
- composition of agent's neighbourhood could be dynamic depending on the structure of the system.

#### Agent decision making

Agents are often designed to make rational recisions: they act to maximise the expected value of their  behaviour given the information they have received so far.

Agent decision making may be:

- probabilistic: representing decisions using distributions
- rule-based: modelling the decision making process
- adaptive: agents may learn via reinforcment or evolution.


#### Agent types

- Reflective agents: percieve some aspect of their environment via sensors and acting according to some set of rules, choose some behaviour or action.
- Reflective agents wtih internal state
- Goal-driven agents: select their action based not only on the current and past states of the world, but also in accordance to some desired future state of world.
- Utilitarian agents: is a refinement of a goal-driven agent, where possible future states are not necessarily assessed against a specific goal state, but rather evaluated according to some utility function.
- Learning agent: is able to adapt the rules that it uses to make choices, in response to some feedback on its past performance. There are a wide variety of approaches to implementing learning in ABMs.

### Complex Networks --- Network Structure

Why study networks:

- more and more data on patterns of interaction is becoming available.
- Network science offers tools to help make sense of this data.
- We can learn something about the functional properties of these systems by studying their structural properties.
- Insights developed in one domain may generalise to other domains.


Doing network allows us to quantify and analyse system structure in terms of relatively simple properties.

#### Network properties
A network consists of:

- A set of nodes or vertices
- A set of edges or links
- Data about nodes and edges

##### Structural Property
- bipartite networks: directors and the companies whose boards they site on; actors and the movies they have appeared in.
- directed network: web pages and the (directed) links between them; food webs with directed edges indicating predation.

##### Density
The density D of a network is the ratio of the number of edges in the network to the numebr of possible edges

A network with N nodes and E edges could have up to $\frac{N(N-1)}{2}$ possible edges, therefore:
$D=\frac{2E}{N(N-1)}$

##### Degree
The degree $k_{i}$ is the number of edges between node i and other nodes in the network. Nodes with high degree are often considered to be more "important".

The average degree \<K\> of a network, where \<K\>=2E/N

The degree distribution P(k) of a network is the probability distribution of degrees over all nodes in the network. $P(k)=N_{k}/N$ where $N_{k} us the number of nodes of degree k

##### Distance
The distance $d_{ij}$ between nodes i and j is the length of the shortest path between those two nodes.

The characteristic path length L is the average distance between all pair of nodes in the network:
$L = \frac{1}{N(N-1)}\sum_{i\neq j}d_{i,j}$

The **diameter** of a network is the longest shortest path between any two nodes.

##### Clustering
The clustering coefficient C is a measure of "cliquishness" in a network.

$C = \frac{T_{c}}{T_{c}+T_{o}}$

$T_{c}$ is the number of closed triplets, sets of three nodes each of which is connected to the other two.

$T_{o}$ is the number of open triplets, sets of three nodes in which exactly node is linked the other two.

The clustering coefficient $C_{i}$ of node defined between the number of edges $E_{i}$  that actually do exist between these $k_{i}$ nodes and the total number $k_{i}(k_{i}-1)/2$ possible

$C_{i} = \frac{2E_{i}}{k_{i}(k_{i}-1)}$

##### Centrality and assortativity

Centrality is another approach to measuring which are the most important nodes or edges in a network. There are many different definitions including

Assortativity measures the extent to which similar nodes tend to be connected to each other.

#### Types of network

- Regular lattices
- Random networks
- Small world networks
- Scale free networks: A scale free network is one whose degree distribution follows a power law distribution
  - An interesting property of scale free networks is that they are highly robust to random error
  - However, a trade-off is that they are highly sensitive to targeted attack.


### Complex Networks --- Network Dynamics

Two types of network dynamic:

- the network structure may remain static, but the state of nodes changes — dynamics on networks
- the network structure changes — dynamics of networks

#### Dynamics on networks


#### Dynamics of networks
The growth model we used for creating scale-free networks and the rewiring model we used for creating small world networks are simple examples of network dynamics

#### Networks and ABMs

In the simplest case, agents are mapped to the nodes of a network, and the network topology determines patterns of interaction between agents.

Network (as opposed to spatial) models are useful when:

- the relationships among agents are more important than their physical locations; eg, a model of information spreading through a population (potentially via phone or email), versus a model of a fire spreading through a forest
- interactions between agents are not grounded in physical proximity; eg, a model of interacting software agents, versus a predator-prey model.


















